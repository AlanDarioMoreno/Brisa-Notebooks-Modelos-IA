{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlanDarioMoreno/Brisa-Notebooks-Modelos-IA/blob/Resnet50-5clases%2FRetino-NoRetino/Entrenamiento_modelo_Resnet50_5Clases_Retino_NoRetino.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Se vincula Google Drive para hacer la precarga de modelos y utilizar los datasets generados\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uINhwFSs3uEd",
        "outputId": "f506edef-23b9-418b-bdc8-441a5b8e14c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ssl\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, datasets, models\n",
        "\n",
        "\n",
        "# Contantes que utilizamos para manejar los distintos tipos de entrenamientos\n",
        "IMAGE_SIZE= 512\n",
        "EPOCS = 4\n",
        "LR = 1e-5\n",
        "BATCH_SIZE = 64\n",
        "NUM_CLASES = 2\n",
        "\n",
        "# Se define la capa GeM que reemplazara al avgPooling de Resnet50\n",
        "def gem(x, p=3, eps=1e-6):\n",
        "    return nn.functional.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
        "\n",
        "class GeM(nn.Module):\n",
        "    def __init__(self, p=3, eps=1e-6):\n",
        "        super(GeM, self).__init__()\n",
        "        self.p = nn.Parameter(torch.ones(1) * p)\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        return gem(x, p=self.p, eps=self.eps)\n",
        "\n",
        "# Declara un PATH para el guardado del entrenamiento o el re-entrenamiento de otro modelo\n",
        "model_path ='/content/drive/MyDrive/Colab/ResNet50/RetinaNoRetina_resnet50_v1.pth'\n",
        "\n",
        "# Cargar el modelo ResNet50 con la capa GeM ya implementada\n",
        "model = models.resnet50(pretrained=False)\n",
        "model.avgpool = GeM()\n",
        "\n",
        "# Ajusta  la cantidad de capas de salida del modelo definido con la constante NUM_CLASES\n",
        "model.fc = nn.Linear(model.fc.in_features, NUM_CLASES)\n",
        "\n",
        "# Intentar cargar el modelo si existe\n",
        "try:\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    print(\"Modelo cargado exitosamente.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Modelo no encontrado, entrenando desde cero.\")\n",
        "\n",
        "# Transformacio de imagen\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Cargar el dataset\n",
        "image_dir = '/content/drive/MyDrive/01Retina-NoRetina'\n",
        "dataset = datasets.ImageFolder(root=image_dir, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# Configuración del dispositivo y criterio de pérdida\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR) # Aqui se aplica el Learning Rate definido por constante. Se fue modificando dependiendo los resultados de los entrenamientos\n",
        "model.to(device)\n",
        "\n",
        "# Función para calcular precisión\n",
        "def calculate_accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    corrects = torch.sum(preds == labels).item()\n",
        "    return corrects / labels.size(0)\n",
        "\n",
        "# Inicializar la mejor pérdida como un valor alto al principio\n",
        "best_loss = float('inf')\n",
        "\n",
        "# Entrenamiento\n",
        "num_epochs = EPOCS\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
        "    running_loss = 0.0\n",
        "    running_accuracy = 0.0\n",
        "    total_batches = 0\n",
        "\n",
        "    model.train()\n",
        "    for images, labels in dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calcular precisión y pérdida para el batch actual\n",
        "        batch_accuracy = calculate_accuracy(outputs, labels)\n",
        "        running_loss += loss.item()\n",
        "        running_accuracy += batch_accuracy\n",
        "        total_batches += 1\n",
        "\n",
        "        # Mostrar precisión y pérdida para cada batch\n",
        "        print(f\"Lote {total_batches} - Loss: {loss.item():.4f} - Accuracy: {batch_accuracy * 100:.2f}%\")\n",
        "\n",
        "    # Promedio de pérdida y precisión por EPOC\n",
        "    epoch_loss = running_loss / total_batches\n",
        "    epoch_accuracy = (running_accuracy / total_batches) * 100\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs} - Loss: {epoch_loss:.4f} - Accuracy: {epoch_accuracy:.2f}%\")\n",
        "\n",
        "    # Guardar el modelo si la pérdida ha disminuido\n",
        "    if epoch_loss < best_loss:\n",
        "        best_loss = epoch_loss\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "        print(f\"Modelo guardado en la época {epoch+1} con pérdida de {epoch_loss:.4f}.\")\n",
        "\n",
        "print(\"Entrenamiento finalizado.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "a56a5266-a268-49f4-db7c-31e0d2aa1ab2",
        "id": "AV-uk6DSxQjl",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-be7af872a675>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mssl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   2473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2475\u001b[0;31m from torch import (\n\u001b[0m\u001b[1;32m   2476\u001b[0m     \u001b[0mexport\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pytree\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpytree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compatibility\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpass_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPassResult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpass_manager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPassManager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m from torch.utils._pytree import (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/fx/passes/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraph_drawer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraph_manipulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnet_min_base\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moperator_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparam_fetch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/fx/passes/graph_drawer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_format_arg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_get_qualified_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperator_schemas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnormalize_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_prop\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorMetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/fx/passes/shape_prop.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compatibility\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdetect_fake_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_subclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_sparse_any\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'TensorMetadata'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ShapeProp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_subclasses/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m from torch._subclasses.fake_tensor import (\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mDynamicOutputShapeException\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mFakeTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mFakeTensorMode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   2407\u001b[0m )\n\u001b[1;32m   2408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2409\u001b[0;31m from torch._subclasses.fake_impls import (  # noqa: F401\n\u001b[0m\u001b[1;32m   2410\u001b[0m     \u001b[0m_device_not_kwarg_ops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2411\u001b[0m     \u001b[0m_is_tensor_constructor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_impls.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m _like_tensor_constructors = ordered_set(\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0maten\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0maten\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0maten\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, op_name)\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m         \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m         opoverloadpacket = OpOverloadPacket(\n\u001b[0m\u001b[1;32m   1237\u001b[0m             \u001b[0mqualified_op_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverload_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, qualified_op_name, op_name, op, overload_names)\u001b[0m\n\u001b[1;32m   1007\u001b[0m \u001b[0;31m# You can obtain an OpOverload object through attribute query.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mOpOverloadPacket\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1009\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqualified_op_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverload_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1010\u001b[0m         \u001b[0;31m# These attributes are accessible on the object through the properties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0;31m# defined below but are immutable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Path del dataset de Test\n",
        "test_image_dir = '/content/drive/MyDrive/TestOjos'\n",
        "\n",
        "# Las imagenes se transforman segun la configuracion del modelo\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Cargar el dataset\n",
        "test_dataset = datasets.ImageFolder(root=test_image_dir, transform=test_transform)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Poner el modelo en modo de evaluación\n",
        "model.eval()\n",
        "model.to(device)\n",
        "\n",
        "# Función para realizar las predicciones\n",
        "def predict_with_outputs_and_names(model, dataloader, dataset):\n",
        "    predictions = []\n",
        "    labels = []\n",
        "    outputs_list = []  # Para almacenar las salidas crudas (logits)\n",
        "    image_names = []   # Para almacenar los nombres de las imágenes\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (images, label) in enumerate(dataloader):\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            outputs_list.extend(outputs.cpu().numpy())  # Guardar las salidas\n",
        "            _, preds = torch.max(outputs, 1)  # Obtener las clases predichas\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "            labels.extend(label.numpy())\n",
        "\n",
        "            # Obtener los nombres de las imágenes desde el dataset\n",
        "            start_idx = i * dataloader.batch_size\n",
        "            end_idx = start_idx + len(images)\n",
        "            image_names.extend([dataset.imgs[idx][0] for idx in range(start_idx, end_idx)])\n",
        "\n",
        "    return predictions, labels, outputs_list, image_names\n",
        "\n",
        "# Realizar predicciones en el dataset de test y obtener las salidas\n",
        "predictions, true_labels, outputs_list, image_names = predict_with_outputs_and_names(model, test_dataloader, test_dataset)\n",
        "\n",
        "# Mostrar las salidas\n",
        "for idx in range(len(image_names)):\n",
        "    print(f\"  Imagen: {image_names[idx]}\")\n",
        "    print(f\"  Salida del modelo: {outputs_list[idx]}\")\n",
        "    print(f\"  Predicción: {predictions[idx]} - Etiqueta Verdadera: {true_labels[idx]}\")\n",
        "    print(\"---------------------------------------------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyqEW95C_dJX",
        "outputId": "4c17f582-b690-4c6c-e699-190fffcb95c3",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Imagen: /content/drive/MyDrive/TestOjos/Mild/11505_left.jpeg\n",
            "  Salida del modelo: [1.8430984  1.02328    1.5348706  0.2960907  0.36236632]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 0\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Mild/11505_right.jpeg\n",
            "  Salida del modelo: [1.6659739  0.98677135 1.557403   0.1618863  0.34237123]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 0\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Mild/11959_left.jpeg\n",
            "  Salida del modelo: [1.6561369  0.79577696 1.7407235  0.36317644 0.50568485]\n",
            "  Predicción: 2 - Etiqueta Verdadera: 0\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Mild/11959_right.jpeg\n",
            "  Salida del modelo: [1.508803   0.8847409  1.630891   0.13751367 0.6142112 ]\n",
            "  Predicción: 2 - Etiqueta Verdadera: 0\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Mild/12139_left.jpeg\n",
            "  Salida del modelo: [4.3866224  1.8054328  1.4747533  0.10074368 1.582581  ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 0\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Mild/12139_right.jpeg\n",
            "  Salida del modelo: [4.475717   1.9874465  1.6229899  0.31646433 1.6161124 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 0\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Mild/16488_left.jpeg\n",
            "  Salida del modelo: [4.248577   1.7988364  1.8464607  0.20693675 1.6129009 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 0\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Mild/16488_right.jpeg\n",
            "  Salida del modelo: [3.316026  1.7388927 1.6677052 0.3714079 1.3005383]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 0\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Mild/16628_left.jpeg\n",
            "  Salida del modelo: [2.4722836  1.2068872  1.5909458  0.43732098 1.0248214 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 0\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Mild/16628_right.jpeg\n",
            "  Salida del modelo: [2.070753   1.0357767  1.4222054  0.43615523 0.8570303 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 0\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Mild/16941_left.jpeg\n",
            "  Salida del modelo: [1.572008   1.0215267  1.5237838  0.39226273 0.5873461 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 0\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Mild/16941_right.jpeg\n",
            "  Salida del modelo: [1.6957572  0.9958005  1.5668534  0.07723525 0.54000115]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 0\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Mild/204_right.jpeg\n",
            "  Salida del modelo: [3.8858206  1.3900305  1.9846957  0.46130267 1.4456273 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 0\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Mild/30_left.jpeg\n",
            "  Salida del modelo: [3.3367329 1.6255587 1.5483998 0.109265  1.3989846]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 0\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Mild/3124_left.jpeg\n",
            "  Salida del modelo: [2.0260594  1.1525544  1.4509974  0.24720362 0.7861165 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 0\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Mild/3124_right.jpeg\n",
            "  Salida del modelo: [1.9546137 1.2053858 1.5189596 0.5422864 0.8065636]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 0\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Mild/3459_left.jpeg\n",
            "  Salida del modelo: [3.6830788  1.051861   1.8600055  0.10284367 1.4123899 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 0\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Mild/3459_right.jpeg\n",
            "  Salida del modelo: [3.274586  1.0898846 1.9103837 0.098133  0.8570491]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 0\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Mild/435_left.jpeg\n",
            "  Salida del modelo: [4.069469   1.2767739  1.7687476  0.09908071 1.4383038 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 0\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Mild/435_right.jpeg\n",
            "  Salida del modelo: [3.6825392  1.6840743  1.7595128  0.13758388 1.4289795 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 0\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Mild/8410_left.jpeg\n",
            "  Salida del modelo: [4.881868  2.0299602 1.6711562 0.6669761 2.1184382]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 0\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Mild/8410_right.jpeg\n",
            "  Salida del modelo: [4.77704   1.819018  1.9313961 0.6658312 1.8639102]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 0\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Moderate/1204_left.jpeg\n",
            "  Salida del modelo: [1.5272444  0.8983015  1.5887109  0.13932994 0.7311541 ]\n",
            "  Predicción: 2 - Etiqueta Verdadera: 1\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Moderate/1204_right.jpeg\n",
            "  Salida del modelo: [1.441596   0.960825   1.5244316  0.44109014 0.5479078 ]\n",
            "  Predicción: 2 - Etiqueta Verdadera: 1\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Moderate/1259_left.jpeg\n",
            "  Salida del modelo: [2.3915205 1.3446313 1.7541763 0.3975177 1.098406 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 1\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Moderate/1259_right.jpeg\n",
            "  Salida del modelo: [2.4121313  1.2158191  1.7226914  0.27135637 0.76311076]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 1\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Moderate/129_left.jpeg\n",
            "  Salida del modelo: [2.465055  1.1670724 1.7324957 0.3280305 0.8908496]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 1\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Moderate/129_right.jpeg\n",
            "  Salida del modelo: [2.2197497  1.2529466  1.7007289  0.35876122 0.81737995]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 1\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Moderate/1419_left.jpeg\n",
            "  Salida del modelo: [2.4962864 1.2736677 1.8508334 0.4577835 0.792221 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 1\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Moderate/1419_right.jpeg\n",
            "  Salida del modelo: [2.3633206  1.2554469  1.7636908  0.29669133 0.727361  ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 1\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Moderate/264_left.jpeg\n",
            "  Salida del modelo: [2.9482138  1.1500463  1.6948717  0.41772202 0.94645184]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 1\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Moderate/264_right.jpeg\n",
            "  Salida del modelo: [3.00413    1.2482628  1.9423066  0.28970316 0.8545246 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 1\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Moderate/3250_left.jpeg\n",
            "  Salida del modelo: [3.9507406  0.91751784 2.111996   0.14056173 1.2474709 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 1\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Moderate/3250_right.jpeg\n",
            "  Salida del modelo: [3.7204037  1.0143936  1.9347771  0.20890346 1.2922049 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 1\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Moderate/3295_left.jpeg\n",
            "  Salida del modelo: [5.4936523 2.454751  2.157675  1.3883389 2.2909355]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 1\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Moderate/3295_right.jpeg\n",
            "  Salida del modelo: [5.282712  2.5592234 2.0172324 1.9393519 2.2130573]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 1\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Moderate/3334_left.jpeg\n",
            "  Salida del modelo: [3.779301  1.2533828 1.8769637 0.2779111 1.1687877]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 1\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Moderate/3334_right.jpeg\n",
            "  Salida del modelo: [3.4276667  1.3155916  1.9211184  0.12924662 1.0126162 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 1\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Moderate/3356_left.jpeg\n",
            "  Salida del modelo: [2.3891697  0.9907019  1.6513484  0.04303601 0.7487494 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 1\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Moderate/3356_right.jpeg\n",
            "  Salida del modelo: [2.927508   1.1723233  1.587371   0.13020447 1.0531597 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 1\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Moderate/4723_left.jpeg\n",
            "  Salida del modelo: [ 3.3601243   0.99029565  1.9466857  -0.1451473   0.6522656 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 1\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Moderate/4723_right.jpeg\n",
            "  Salida del modelo: [2.7362003  0.9658904  1.8925916  0.07689562 0.684178  ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 1\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Moderate/4824_left.jpeg\n",
            "  Salida del modelo: [3.7457566  1.2789998  1.8041908  0.12885013 1.5451119 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 1\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Moderate/4824_right.jpeg\n",
            "  Salida del modelo: [5.0122347 1.5465566 2.187487  1.2655538 1.9425044]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 1\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/No_DR/140_left.jpeg\n",
            "  Salida del modelo: [3.8939133 2.1119556 1.9309343 1.2553066 2.0888398]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 2\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/No_DR/140_right.jpeg\n",
            "  Salida del modelo: [3.7872856 2.4038136 2.063632  1.1281694 2.1706946]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 2\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/No_DR/1488_left.jpeg\n",
            "  Salida del modelo: [3.7029145  1.5742644  2.1488087  0.39467087 1.481351  ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 2\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/No_DR/1488_right.jpeg\n",
            "  Salida del modelo: [4.238735   1.8073102  1.7343282  0.63790023 1.8344779 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 2\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/No_DR/1507_left.jpeg\n",
            "  Salida del modelo: [4.1025033 1.734341  2.0798247 0.428924  1.4331623]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 2\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/No_DR/1507_right.jpeg\n",
            "  Salida del modelo: [3.9470608 1.5593792 2.1102498 0.2510871 1.1987206]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 2\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/No_DR/1508_left.jpeg\n",
            "  Salida del modelo: [1.9079884  0.9077877  1.7355164  0.13156638 0.56466997]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 2\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/No_DR/1508_right.jpeg\n",
            "  Salida del modelo: [2.1923442  0.95482844 1.7785395  0.10378399 0.63475657]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 2\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/No_DR/1509_left.jpeg\n",
            "  Salida del modelo: [1.4168222  1.0503508  1.4869479  0.3115051  0.72884417]\n",
            "  Predicción: 2 - Etiqueta Verdadera: 2\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/No_DR/1513_left.jpeg\n",
            "  Salida del modelo: [2.1615798  1.1375756  1.7559961  0.03586653 0.49791753]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 2\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/No_DR/1513_right.jpeg\n",
            "  Salida del modelo: [1.9935843  0.8893019  1.739375   0.22073689 0.548753  ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 2\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/No_DR/161_left.jpeg\n",
            "  Salida del modelo: [2.3886683 1.1428334 1.8469629 0.0379273 0.5830709]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 2\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/No_DR/161_right.jpeg\n",
            "  Salida del modelo: [2.247713   1.2751272  1.6610857  0.22868553 0.5029647 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 2\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/No_DR/288_left.jpeg\n",
            "  Salida del modelo: [2.07944    1.1556454  1.6454225  0.22831777 0.9046884 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 2\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/No_DR/288_right.jpeg\n",
            "  Salida del modelo: [2.3326294 1.2482332 1.5001484 0.2182962 1.0783273]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 2\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/No_DR/625_left.jpeg\n",
            "  Salida del modelo: [3.4163444 1.2567806 1.7224009 0.2661982 0.8677514]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 2\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/No_DR/625_right.jpeg\n",
            "  Salida del modelo: [3.3496268  1.3219483  1.8859652  0.17987815 0.95321476]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 2\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/No_DR/966_left.jpeg\n",
            "  Salida del modelo: [2.2995522  1.1872565  1.768705   0.23110011 0.79363835]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 2\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/No_DR/966_right.jpeg\n",
            "  Salida del modelo: [2.3998249  1.2810581  1.7232239  0.37840202 0.96046215]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 2\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Proliferative/13066_right.jpeg\n",
            "  Salida del modelo: [3.3412824  1.082799   1.7184638  0.12964347 1.0996386 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 3\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Proliferative/13819_right.jpeg\n",
            "  Salida del modelo: [ 3.2716064   1.6367385   1.8014024  -0.20235023  1.4187478 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 3\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Proliferative/14495_right.jpeg\n",
            "  Salida del modelo: [3.2400656  1.0401706  1.8627174  0.32381693 0.8517886 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 3\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Proliferative/34901_left.jpeg\n",
            "  Salida del modelo: [2.0411482 1.0829082 1.2718387 0.7005545 1.1345493]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 3\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Proliferative/34901_right.jpeg\n",
            "  Salida del modelo: [2.0850124  1.175258   1.5567461  0.40938416 0.78827655]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 3\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Proliferative/35412_left.jpeg\n",
            "  Salida del modelo: [2.0850964  1.2277133  1.7121814  0.43867972 0.9358202 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 3\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Proliferative/36074_left.jpeg\n",
            "  Salida del modelo: [4.1558995 1.683326  1.7437401 0.1643447 1.432091 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 3\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Proliferative/38407_left.jpeg\n",
            "  Salida del modelo: [3.6344388  1.42342    1.9957519  0.45754567 0.9998595 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 3\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Proliferative/38407_right.jpeg\n",
            "  Salida del modelo: [3.5049715  1.3737316  2.0980945  0.39448443 1.2063123 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 3\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Proliferative/43008_left.jpeg\n",
            "  Salida del modelo: [3.8153698 1.3825536 1.8652599 0.0885736 1.4349128]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 3\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Proliferative/43050_left.jpeg\n",
            "  Salida del modelo: [4.143693  1.5690458 2.2391677 0.704944  1.4259182]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 3\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Proliferative/44100_left.jpeg\n",
            "  Salida del modelo: [5.2088604 2.4677594 1.8711414 1.6087197 2.1967056]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 3\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Proliferative/6719_left.jpeg\n",
            "  Salida del modelo: [3.2565951  1.0518987  1.9307005  0.0303376  0.92563593]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 3\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Proliferative/6719_right.jpeg\n",
            "  Salida del modelo: [ 3.208995    1.2174865   1.8447164  -0.03020034  0.861687  ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 3\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Proliferative/6997_right.jpeg\n",
            "  Salida del modelo: [ 2.7664294   0.9537368   1.918056   -0.31795952  0.66264814]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 3\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Severe/1177_left.jpeg\n",
            "  Salida del modelo: [2.1046448  1.2100235  1.7916749  0.34029856 0.7517427 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 4\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Severe/1177_right.jpeg\n",
            "  Salida del modelo: [2.0769966  1.2135253  1.7510375  0.53906095 0.76918316]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 4\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Severe/12612_left.jpeg\n",
            "  Salida del modelo: [1.9279449  1.2115557  1.386098   0.4417037  0.83344233]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 4\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Severe/12612_right.jpeg\n",
            "  Salida del modelo: [1.9894257  1.0303583  1.416362   0.41235057 0.8895104 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 4\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Severe/14109_left.jpeg\n",
            "  Salida del modelo: [1.9506794  1.1526558  1.4123738  0.52611434 0.82580507]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 4\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Severe/14109_right.jpeg\n",
            "  Salida del modelo: [1.8932669 1.1505467 1.3343859 0.4922935 0.8669638]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 4\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Severe/27489_left.jpeg\n",
            "  Salida del modelo: [ 3.8145404   1.4632926   1.6325041  -0.12892231  1.5220329 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 4\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Severe/27489_right.jpeg\n",
            "  Salida del modelo: [4.2474356  1.4152825  1.7780012  0.05602017 1.1537436 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 4\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Severe/27768_left.jpeg\n",
            "  Salida del modelo: [4.287669  2.0617397 2.2441883 1.0080839 1.3565414]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 4\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Severe/27768_right.jpeg\n",
            "  Salida del modelo: [4.0761576 1.8001399 1.6181933 1.2496353 1.9825041]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 4\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Severe/28093_right.jpeg\n",
            "  Salida del modelo: [2.3581297  1.1650562  1.6725967  0.37213448 0.82978433]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 4\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Severe/28405_right.jpeg\n",
            "  Salida del modelo: [2.4827387 1.1164342 1.9574505 0.1807932 0.7860557]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 4\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Severe/28919_right.jpeg\n",
            "  Salida del modelo: [3.1017685  1.2517471  2.0202596  0.10126749 0.977173  ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 4\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Severe/28975_right.jpeg\n",
            "  Salida del modelo: [2.4777496  1.1905265  1.8363264  0.25653973 0.837294  ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 4\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Severe/3422_left.jpeg\n",
            "  Salida del modelo: [3.6393583  1.1825134  2.1794987  0.33973876 1.1382545 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 4\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Severe/3422_right.jpeg\n",
            "  Salida del modelo: [3.6805878  1.0070682  1.9959685  0.23197952 1.2063768 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 4\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Severe/36989_left.jpeg\n",
            "  Salida del modelo: [3.8316522  1.5495172  1.9200084  0.14248314 1.3792948 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 4\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Severe/36989_right.jpeg\n",
            "  Salida del modelo: [3.704813   1.5717641  1.7029098  0.24314705 1.2210165 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 4\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Severe/37032_left.jpeg\n",
            "  Salida del modelo: [2.8525088  0.9532787  1.8773735  0.14854828 1.0726728 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 4\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Severe/37032_right.jpeg\n",
            "  Salida del modelo: [3.223622   1.1067882  1.8204721  0.11680499 1.1148089 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 4\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Severe/37339_left.jpeg\n",
            "  Salida del modelo: [3.2465978  1.3139914  1.6854655  0.08663264 0.9338473 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 4\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Severe/38016_left.jpeg\n",
            "  Salida del modelo: [ 3.392957    1.5578982   1.7263632  -0.30687687  1.0802413 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 4\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Severe/38198_right.jpeg\n",
            "  Salida del modelo: [3.6552088 1.3255938 1.9147706 0.0647005 1.2030342]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 4\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Severe/7959_left.jpeg\n",
            "  Salida del modelo: [2.816979   1.0513788  1.868659   0.03775396 0.7520449 ]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 4\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Severe/7959_right.jpeg\n",
            "  Salida del modelo: [3.1555457  1.1964916  1.7310059  0.03473064 0.95129037]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 4\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Severe/8678_left.jpeg\n",
            "  Salida del modelo: [1.3617024  0.8641273  1.5280395  0.20893447 0.5348966 ]\n",
            "  Predicción: 2 - Etiqueta Verdadera: 4\n",
            "---------------------------------------------------------------------------\n",
            "  Imagen: /content/drive/MyDrive/TestOjos/Severe/8678_right.jpeg\n",
            "  Salida del modelo: [1.4821355  0.94562    1.474728   0.01784959 0.49591374]\n",
            "  Predicción: 0 - Etiqueta Verdadera: 4\n",
            "---------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "# Función para calcular la precisión por clase\n",
        "def accuracy_per_class(predictions, true_labels, num_classes):\n",
        "    correct_counts = defaultdict(int)  # Correct predictions per class\n",
        "    total_counts = defaultdict(int)    # Total predictions per class\n",
        "\n",
        "    for pred, true in zip(predictions, true_labels):\n",
        "        total_counts[true] += 1\n",
        "        if pred == true:\n",
        "            correct_counts[true] += 1\n",
        "\n",
        "    # Calcular porcentaje de precisión por clase\n",
        "    accuracy_per_class = {}\n",
        "    for cls in range(NUM_CLASES):\n",
        "        if total_counts[cls] > 0:\n",
        "            accuracy_per_class[cls] = (correct_counts[cls] / total_counts[cls]) * 100\n",
        "        else:\n",
        "            accuracy_per_class[cls] = 0.0  # Si no hay ejemplos de la clase, precisión es 0\n",
        "\n",
        "    return accuracy_per_class\n",
        "\n",
        "# Obtener el porcentaje de aciertos por clase\n",
        "accuracy_per_class_results = accuracy_per_class(predictions, true_labels, NUM_CLASES)\n",
        "\n",
        "# Mostrar resultados de precisión por clase\n",
        "for cls, acc in accuracy_per_class_results.items():\n",
        "    print(f\"Clase {cls}: {acc:.2f}% de aciertos\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qH0S6gSADvod",
        "outputId": "27bddd9d-c9c9-4d28-b051-13e0b08e27dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clase 0: 90.91% de aciertos\n",
            "Clase 1: 0.00% de aciertos\n",
            "Clase 2: 5.26% de aciertos\n",
            "Clase 3: 0.00% de aciertos\n",
            "Clase 4: 0.00% de aciertos\n"
          ]
        }
      ]
    }
  ]
}